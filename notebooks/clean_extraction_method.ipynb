{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Extraction Method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just a cleaner version of \"extraction_data.ipynb\", its objective is to provide a clearer methodology of data generation. Though, it is not certain that it will cover all the materials that \"extraction_data.ipynb\" covered. Then, take it as a complement for the ease of the lector rather than a subsitute for the developper."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample_2023_with_txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This how we generated the data set sample_2023_woth_txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate the file with the sample of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def import_sample(file, format:str, begin=None, end=None):\n",
    "    if format == 'excel':\n",
    "        df = pd.read_excel(file).iloc[begin:end]\n",
    "        print(df.info())\n",
    "        return df\n",
    "    elif format == 'csv':\n",
    "        df = pd.read_csv(file).iloc[begin:end]\n",
    "        print(df.info())\n",
    "        return df\n",
    "    else:\n",
    "        print('Please provide a valid format (excel or csv)')\n",
    "\n",
    "df_samp = import_sample(r'C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample2023.xlsx', 'excel', 0, 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp.columns\n",
    "df_samp_final = df_samp[[\n",
    "    'UrlLegifrance', \n",
    "    'Entreprise', \n",
    "    'Siret', \n",
    "    'Secteur', \n",
    "    # 'Nature', \n",
    "    # 'Titre',\n",
    "    'Naf732', \n",
    "    'Date Texte', \n",
    "    # 'Date Maj', \n",
    "    # 'Date Dépot', \n",
    "    # 'Date diffusion',\n",
    "    # 'Date fin', \n",
    "    # 'LesSyndicats', \n",
    "    # 'LesThemes', \n",
    "    # 'type',\n",
    "    'Tranche Effectif(Base siren)', \n",
    "    'Fichier', \n",
    "    # 'ID'\n",
    "    ]].copy()\n",
    "df_samp_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the application year\n",
    "df_samp_final[\"Année d'application NAO\"] = 2023\n",
    "df_samp_final[\"code\"] = df_samp_final[\"Fichier\"].str.slice(101,113)\n",
    "df_samp_final.head(10)\n",
    "\n",
    "# Reorder the columns\n",
    "df_samp_final.columns\n",
    "df_samp_final = df_samp_final[[\n",
    "    # 'UrlLegifrance',\n",
    "    'code',\n",
    "    'Entreprise', \n",
    "    'Siret', \n",
    "    'Secteur', \n",
    "    'Naf732', \n",
    "    'Date Texte',\n",
    "    \"Année d'application NAO\",\n",
    "    'Tranche Effectif(Base siren)', \n",
    "    ]].copy()\n",
    "\n",
    "# Rename the columns\n",
    "df_samp_final.columns = [\"code\",\"Nom de l'entreprise\", \"Siret\", \"Sous secteur Secafi\", \"Code NAF\", \"Date de l'accord du texte\", \"Année d'application NAO\", \"Tranche Effectif (Base siren)\"]\n",
    "\n",
    "df_samp_final.head(10)\n",
    "df_samp_final.to_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample_2023_no_txt.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second we create the file with the corresponding code txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "df_sample = pd.read_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample2023.xlsx\") # this sample has been directly extracted from Qlik Sense plateform\n",
    "\n",
    "# We select the columns we want to keep\n",
    "df_sample = df_sample[[\n",
    "    'UrlLegifrance', \n",
    "    # 'Entreprise', \n",
    "    # 'Siret', \n",
    "    # 'Secteur', \n",
    "    # 'Nature', \n",
    "    # 'Titre',\n",
    "    # 'Naf732', \n",
    "    # 'Date Texte', \n",
    "    # 'Date Maj', \n",
    "    # 'Date Dépot', \n",
    "    # 'Date diffusion',\n",
    "    # 'Date fin', \n",
    "    # 'LesSyndicats', \n",
    "    # 'LesThemes', \n",
    "    # 'type',\n",
    "    # 'Tranche Effectif(Base siren)', \n",
    "    'Fichier', \n",
    "    'ID'\n",
    "    ]].copy()\n",
    "\n",
    "# We create a new column with the ID shortened and the column reordered\n",
    "df_sample[\"code\"] = df_sample[\"Fichier\"].str.slice(101,113)\n",
    "df_sample = df_sample[['UrlLegifrance', 'code','Fichier']].copy()\n",
    "df_sample.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective now is to extract the texts stored on our local data center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a list of the unique ID_b and write in a doc file\n",
    "\n",
    "def write_column_to_txt(df, column, path):\n",
    "    \"\"\"\n",
    "    Write the content of a column of a dataframe in a txt file\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): the dataframe\n",
    "        column (str): the column to write\n",
    "        path (str): the path of the txt file\n",
    "    \"\"\"\n",
    "    with open(path, 'w') as f:\n",
    "        for item in df[column].unique():\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "write_column_to_txt(df_sample, \"Fichier\", r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\docx\\2022_2023\\sample_2023\\Liste.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download each of the txt files, we have to do this manually, since the program doesn't provide me access"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert each of this text to the txt format, for that we can use the two following scripts : convert_to_txt_V2.py and clean_txt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Specify the path to the folder containing the Python scripts\n",
    "script_folder = r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\script\"\n",
    "\n",
    "# Define the names of the Python scripts you want to run\n",
    "script1_name = \"convert_to_txt_V2.py\"\n",
    "script2_name = \"clean_txt.py\"\n",
    "\n",
    "# Build the full paths to the script files\n",
    "script1_path = os.path.join(script_folder, script1_name)\n",
    "script2_path = os.path.join(script_folder, script2_name)\n",
    "\n",
    "# Run the first script\n",
    "subprocess.run([\"python\", script1_path])\n",
    "\n",
    "# Run the second script\n",
    "subprocess.run([\"python\", script2_path])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do a data set out of the document and match their ID to the one of our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\docx\\2017_2021\\Subset_1\\text\\*.txt\")\n",
    "\n",
    "# iniate an empty dataframe\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(directory):\n",
    "    # collect the file name and store it in a list\n",
    "    file_name = os.path.basename(file)[:-19]\n",
    "    \n",
    "    # collect the file content and store it in a list\n",
    "    collected_text = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        collected_text.append(text)\n",
    "\n",
    "    df = pd.DataFrame(collected_text , columns=['text'])\n",
    "    df.insert(0, 'code', file_name)\n",
    "    final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "final_df.to_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample_2017_2021_sub1.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction and matching of text for a sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build on what we did for the NAO 2023 to extract and matcht the text with their respective contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample_2023_no_txt.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We match it with our text data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = pd.read_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample2023_txt.xlsx\")\n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, df_text, on=\"code\", how='left')\n",
    "\n",
    "#Cleaning the dataframe\n",
    "df_merged.dropna(subset=['text'], inplace=True)\n",
    "df_merged['text'] = df_merged['text'].str.replace(r'^\\s+', '', regex=True)\n",
    "df_merged['text'] = df_merged['text'].str.replace(r'\\s+$', '', regex=True)\n",
    "\n",
    "# Reduce the data set to two three columns\n",
    "df_merged = df_merged[[\n",
    "    \"Nom de l'entreprise\", \n",
    "    'code', \n",
    "    # 'Siret', \n",
    "    # 'Sous secteur Secafi',\n",
    "    # 'Code NAF', \n",
    "    # \"Date de l'accord du texte\", \n",
    "    # \"Année d'application NAO\",\n",
    "    # 'Tranche Effectif (Base siren)', \n",
    "    'text'\n",
    "    ]].copy()\n",
    "\n",
    "df_merged.head()\n",
    "\n",
    "# Save the dataframe\n",
    "df_merged.to_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample2023_with_txt.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text and ID Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\docx\\2022_2023\\2022_2023_all\\Subset_1\\text\\*.txt\")\n",
    "\n",
    "def cleaning_function(df):\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    df['text'] = df['text'].str.replace(r'^\\s+', '', regex=True)\n",
    "    df['text'] = df['text'].str.replace(r'\\s+$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "# iniate an empty dataframe\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(directory):\n",
    "    # collect the file name and store it in a list\n",
    "    file_name = os.path.basename(file)[:-19]\n",
    "    \n",
    "    # collect the file content and store it in a list\n",
    "    collected_text = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        collected_text.append(text)\n",
    "\n",
    "    df = pd.DataFrame(collected_text , columns=['text'])\n",
    "    df.insert(0, 'code', file_name)\n",
    "    final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "final_df = cleaning_function(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"len\"] = final_df[\"text\"].agg(lambda x: len(x))\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample_2022_2023_sub1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
