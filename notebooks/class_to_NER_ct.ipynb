{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier to NER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will first used a model to automate the classification of data and then apply the corresponding NER model to optimize the retrieval process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specific case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = r'..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(classifier_model, data, label):\n",
    "    \"\"\"\n",
    "    This function takes in text stored in csv file and outputs two lists of text for the different labels.\n",
    "    \n",
    "    args:\n",
    "        classifier_model: the path to the model used to classify the text\n",
    "        data: the path to the csv file containing the text\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the model and data\n",
    "    nlp_classify = spacy.load(classifier_model)\n",
    "    data = pd.read_csv(data)\n",
    "\n",
    "    # Extract the text from the data and class them\n",
    "    texts = data[\"text\"].tolist()\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp_classify(text)\n",
    "\n",
    "    # Store them in corresponding lists\n",
    "    ppv_list = []\n",
    "    nppv_list = []\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp_classify(text)\n",
    "        if doc.cats.get(label, 0.0) > doc.cats.get(f\"N{label}\", 0.0):\n",
    "            ppv_list.append(text)\n",
    "        else:\n",
    "            nppv_list.append(text)\n",
    "    return ppv_list, nppv_list\n",
    "\n",
    "def NER(ner_model, list:list):\n",
    "    \"\"\"\n",
    "    This function takes in a list of text and outputs a list of tuples containing the text and the predicted NER labels.\n",
    "\n",
    "    args:\n",
    "        ner_model: the path to the model used to predict the NER labels\n",
    "        list: the list of text to be predicted\n",
    "    \"\"\"\n",
    "    nlp_ner = spacy.load(ner_model)\n",
    "\n",
    "    # Initialize an empty list to store the output data\n",
    "    output_data = []\n",
    "\n",
    "    # Loop through items in the directory\n",
    "    for text in list:\n",
    "        doc = nlp_ner(text)\n",
    "        \n",
    "        # Extract labeled information\n",
    "        labeled_data = [\n",
    "            {\n",
    "                \"start\": ent.start_char,\n",
    "                \"end\": ent.end_char,\n",
    "                \"labels\": ent.label_\n",
    "            }\n",
    "            for ent in doc.ents\n",
    "        ]\n",
    "\n",
    "        # Store text and labeled_data as a tuple and append to the output_data list\n",
    "        output_data.append((text, {\"label\": labeled_data}))\n",
    "    return output_data\n",
    "\n",
    "def open_json(json_file:str):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_NER_to_json(list:list, output_path:str):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(list, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "def json_file_length(json_file:str):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    lenght = len(data)\n",
    "    print(\"Le dossier JSON contient\", lenght, \"éléments.\")\n",
    "\n",
    "def NER_pipeline(classifier_model, ner_model, data_input, output_path,label):\n",
    "    \"\"\"\n",
    "    This function takes a classifier model, data input, and an output file path.\n",
    "    It classifies the text using the classifier model and then applies the NER model\n",
    "    to the classified text, returning a JSON file of predicted NER labels.\n",
    "\n",
    "    Args:\n",
    "        classifier_model: The path to the model used to classify the text.\n",
    "        ner_model: The path to the model used to predict the NER labels.\n",
    "        data_input: The path to the CSV file containing the text.\n",
    "        output_path: The path to the JSON file to store the predicted NER labels.\n",
    "    \"\"\"\n",
    "    # Use the classify function to classify the data\n",
    "    ppv_list, nppv_list = classify(classifier_model, data_input,label)\n",
    "\n",
    "    # Use the NER function to predict the NER labels\n",
    "    ppv_output = NER(ner_model, ppv_list)\n",
    "\n",
    "    # Save the predicted NER labels to a JSON file\n",
    "    save_NER_to_json(ppv_output, output_path)\n",
    "\n",
    "    # Print the length of the JSON file\n",
    "    json_file_length(output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = ['OUV', 'INT', 'CAD', 'NOUV', 'NCAD', 'AG', 'AI', 'TOUS', 'AG OUV', 'AG INT', 'AG CAD', 'AI OUV', 'AI INT', 'AI CAD', 'NOUV AG', 'NCAD AG', 'NOUV AI', 'NCAD AI', 'ATOT',\\\n",
    "        'ATOT OUV', 'ATOT INT', 'ATOT CAD', 'PPV', 'PPVm', 'DATE']\n",
    "\n",
    "!mkdir ../data/predicted_json 2> /dev/null\n",
    "\n",
    "for LABEL in all :\n",
    "    LABEL_UNDERSCORE=LABEL.replace(\" \",\"_\")\n",
    "    CLASSIFIER_PATH=os.path.join(ROOT_PATH, f\"models/classifyer/{LABEL_UNDERSCORE}/model-best\")\n",
    "    NER_PATH=os.path.join(ROOT_PATH, f\"models/NER/{LABEL_UNDERSCORE}/model-best\")\n",
    "    DATA_PATH=os.path.join(ROOT_PATH, r\"data/processed/data449_cleaned.csv\")\n",
    "    OUTPUT_PATH=os.path.join(ROOT_PATH, f\"data/predicted_json/labeled_data_{LABEL_UNDERSCORE}_class_to_NER.json\")\n",
    "    NER_pipeline(classifier_model=CLASSIFIER_PATH, ner_model=NER_PATH, data_input=DATA_PATH, output_path=OUTPUT_PATH,label=LABEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
