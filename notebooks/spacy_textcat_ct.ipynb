{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Text Categorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here will be to build a french langage categorizer suited to distinguish different kind of wage agreement components."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some inspiring sources:\n",
    "- https://medium.com/@johnidouglasmarangon/building-a-text-classification-model-with-spacy-3-x-57e59fa50547\n",
    "- https://www.machinelearningplus.com/nlp/custom-text-classification-spacy/\n",
    "- https://www.width.ai/post/spacy-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from spacy.tokens import DocBin\n",
    "import spacy\n",
    "\n",
    "ROOT_PATH = r\"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_label_studio_data(filename, target_labels):\n",
    "    \"\"\"\n",
    "    This function imports the data from Label Studio JSON file and returns the data in the format required for training.\n",
    "    It also allows to select specific labels to train the model on with the \"target_labels\" argument.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(target_labels, list):\n",
    "        raise ValueError(\"The 'target_labels' argument must be a list of strings.\")\n",
    "\n",
    "    TRAIN_DATA = []  # Initialize TRAIN_DATA\n",
    "    \n",
    "    with open(filename, 'rb') as fp:\n",
    "        training_data = json.load(fp)\n",
    "    for text in training_data:\n",
    "        entities = []\n",
    "        info = text.get('text')\n",
    "        entities = []\n",
    "        if text.get('label') is not None:\n",
    "            list_ = []\n",
    "            for label in text.get('label'):\n",
    "                list_.append([label.get('start'), label.get('end')])\n",
    "            a = np.array(list_)\n",
    "            overlap_ind = []\n",
    "            for i in range(0, len(a[:, 0])):\n",
    "                a_comp = a[i]\n",
    "                x = np.delete(a, (i), axis=0)\n",
    "                overlap_flag = any([a_comp[0] in range(j[0], j[1] + 1) for j in x])\n",
    "                if overlap_flag:\n",
    "                    overlap_ind.append(i)\n",
    "\n",
    "            for ind, label in enumerate(text.get('label')):\n",
    "                if ind in overlap_ind:\n",
    "                    iop = 0\n",
    "                else:\n",
    "                    if any(target in label.get('labels') for target in target_labels):\n",
    "                        entities.append((label.get('start'), label.get('end'), label.get('labels')[0]))\n",
    "        \n",
    "        if entities:  # Proceed only if there are non-empty entities\n",
    "            TRAIN_DATA.append((info, {\"entities\": entities}))\n",
    "\n",
    "    return TRAIN_DATA\n",
    "\n",
    "def spacy_to_dataframe(data):\n",
    "    \"\"\"\n",
    "    This function takes the data in the format returned by the import_label_studio_data function and returns a pandas dataframe of two columns: text and label.\n",
    "\n",
    "    Args:\n",
    "        data: The data in the format returned by the import_label_studio_data function.\n",
    "\n",
    "    Returns:\n",
    "        A pandas dataframe of two columns: text and label.\n",
    "    \"\"\"\n",
    "    text_data = [text for text, _ in data]\n",
    "    labels = [label for _, label in data]\n",
    "\n",
    "    df = pd.DataFrame({'text': text_data, 'label': labels})\n",
    "    return df\n",
    "\n",
    "def dummy_label(df,label):\n",
    "    \"\"\"\n",
    "    This function creates a dummy variable for the target label.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame containing the text and label columns.\n",
    "    \"\"\"\n",
    "    # Create a new column called \"label_dummy\" and initialize with zeros\n",
    "    df[\"label_dummy\"] = 0\n",
    "\n",
    "    # Iterate through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        labels = row[\"label\"][\"entities\"]  # Access the entities list in the tuple\n",
    "        if label in set(map(lambda x:x[2],labels)):\n",
    "            df.at[index, \"label_dummy\"] = 1  # Set the value to 1 for the current row\n",
    "    return df\n",
    "\n",
    "#cleaning function : \n",
    "def clean_dataset(data):\n",
    "    \"\"\"\n",
    "    This function cleans the dataset by removing rows with missing values and dropping the \"label\" column.\n",
    "    It also renames the \"label_dummy\" column to \"label\".\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The DataFrame containing the text, label and label_dummy columns.\n",
    "    \"\"\"\n",
    "    data.dropna(axis=0, how='any', inplace=True)\n",
    "    # Now we can drop the \"label\" column and rename the \"label_dummy\" column to \"label\"\n",
    "    if 'label_dummy' in data.columns:\n",
    "        data.drop(\"label\", axis=1, inplace=True)\n",
    "        data.rename(columns={\"label_dummy\": \"label\"}, inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "    return data\n",
    "\n",
    "#We inverse the label to have 0 for PPV and 1 for the rest\n",
    "def inverse_label(data):\n",
    "    \"\"\"\n",
    "    This function inverses the label column.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The DataFrame containing the text and label columns.\n",
    "    \"\"\"\n",
    "    data[\"label\"] = data[\"label\"].apply(lambda x: 0 if x == 1 else 1)\n",
    "    return data\n",
    "\n",
    "def split_data(data, train_ratio=0.75, val_ratio=0.15, test_ratio=0.10, random_seed=None):\n",
    "    \"\"\"\n",
    "    Split a dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - data: The dataset to be split.\n",
    "    - train_ratio: The ratio of data to be allocated to the training set (default: 0.75).\n",
    "    - val_ratio: The ratio of data to be allocated to the validation set (default: 0.15).\n",
    "    - test_ratio: The ratio of data to be allocated to the test set (default: 0.10).\n",
    "    - random_seed: Seed for the random shuffling (default: None, which results in non-reproducible shuffling).\n",
    "\n",
    "    Returns:\n",
    "    - A tuple containing three sets: (train_set, val_set, test_set)\n",
    "    \"\"\"\n",
    "    # Calculate the total size of the dataset\n",
    "    total_size = len(data)\n",
    "    \n",
    "    # Calculate the sizes of each split\n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * val_ratio)\n",
    "    test_size = total_size - train_size - val_size\n",
    "    \n",
    "    # Set the random seed if provided\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    shuffled_data = np.random.permutation(data)\n",
    "    shuffled_data =list(map(lambda x:(str(x[0]),int(x[1])),shuffled_data))\n",
    "\n",
    "    # Split the data into three sets\n",
    "    train_set = shuffled_data[:train_size]\n",
    "    val_set = shuffled_data[train_size:train_size + val_size]\n",
    "    test_set = shuffled_data[train_size + val_size:]\n",
    "    \n",
    "    # Print the size of each set\n",
    "    print(\"Training set size:\", len(train_set))\n",
    "    print(\"Validation set size:\", len(val_set))\n",
    "    print(\"Test set size:\", len(test_set))\n",
    "\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def convert(data, outfile, str_label):\n",
    "    nlp = spacy.blank(\"fr\")\n",
    "    db = DocBin()\n",
    "    \n",
    "    for doc, label in nlp.pipe(data, as_tuples=True):\n",
    "        doc.cats[str_label] = label == 0\n",
    "        doc.cats[\"{str_label}\"] = label == 1\n",
    "        db.add(doc)\n",
    "    db.to_disk(outfile)\n",
    "    print(\"Data saved to:\", outfile)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to adapt the data from label studio to the required format for spacy TextCategorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = ['OUV', 'INT', 'CAD', 'NOUV', 'NCAD', 'AG', 'AI', 'TOUS', 'AG OUV', 'AG INT', 'AG CAD', 'AI OUV', 'AI INT', 'AI CAD', 'NOUV AG', 'NCAD AG', 'NOUV AI', 'NCAD AI', 'ATOT',\\\n",
    "        'ATOT OUV', 'ATOT INT', 'ATOT CAD', 'PPV', 'PPVm', 'DATE']\n",
    "\n",
    "for LABEL in all : \n",
    "    MODEL_PATH=os.path.join(ROOT_PATH,\"models/classifyer\",f\"{LABEL.replace(' ','_')}/\")\n",
    "    !mkdir -p {MODEL_PATH} 2> /dev/null\n",
    "    data = import_label_studio_data(os.path.join(ROOT_PATH, r\"data/raw/data449.json\"), all)\n",
    "    df = spacy_to_dataframe(data)\n",
    "    df = dummy_label(df,LABEL)\n",
    "    df = clean_dataset(df)\n",
    "    dataset = list(df[[\"text\", \"label\"]].sample(frac=1).itertuples(index=False, name=None))\n",
    "    train_data, val_data, test_data = split_data(dataset)\n",
    "    convert(train_data, os.path.join( MODEL_PATH, \"train.spacy\"),LABEL)\n",
    "    convert(val_data, os.path.join( MODEL_PATH, \"val.spacy\"),LABEL)\n",
    "    convert(test_data, os.path.join( MODEL_PATH, \"test.spacy\"),LABEL)\n",
    "    !python -m spacy init config --lang fr --pipeline textcat --optimize efficiency --force {MODEL_PATH}/config.cfg \n",
    "    !python -m spacy train {MODEL_PATH}/config.cfg --paths.train {MODEL_PATH}/train.spacy  --paths.dev {MODEL_PATH}/val.spacy --output {MODEL_PATH}/ --verbose"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
