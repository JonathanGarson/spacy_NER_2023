{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We build the training data base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective here will be to create out of different hand-coded dataset a unique training dataset for our model. For that: \n",
    "- 1. We will clean the different dataset\n",
    "- 2. Concat them into one\n",
    "- 3. Look into our final dataset to determine whether the length of text is too long or not (due to the token limit of transformer models)\n",
    "- 4. Once cleaned we will divide it into 7 subdataset, one for each indicator\n",
    "- 5. final step is to tokenize and embed but it will be for another notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAO_pharma_merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a file out of the necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read i+n the data\n",
    "df = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\selected_text.xlsx')\n",
    "\n",
    "df.columns = [\"proapp_link\"]\n",
    "df['code'] = df['proapp_link'].str.slice(101,113)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the encoded document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\200_NAO.xlsx', sheet_name='Merged')\n",
    "df2_1 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_pharma_carton.xlsx', sheet_name='Saisie')\n",
    "df2_2 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\Echantillon pharma 2023.xlsx', sheet_name='Echantillon final ')\n",
    "df2_3 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\Echantillon NAO papier carton.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_2 = pd.concat([df2_2, df2_3], axis=0, ignore_index=True)\n",
    "df2_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df2_1, df2_2, how='left', left_on=\"Nom de l'entreprise \", right_on='Entreprise')\n",
    "df2_r = df2[[\"Nom de l'entreprise \", \"Siret_x\", \n",
    "        # 'Sous secteur Secafi _x',\n",
    "    #    'Secteur NAF ', 'Code NAF', \n",
    "       \"Date de l'accord du texte\",\n",
    "    #    'Année d'application NAO', 'Tranche Effectif (Base siren)',\n",
    "       'Augmentations générales-Toutes catégories confondues ',\n",
    "       'Augmentations générales-Cadres/ingénieurs',\n",
    "       'Augmentations générales-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "       'Augmentations générales-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations générales-Talon (€)',\n",
    "       'Augmentations individuelles-Toutes catégories confondues ',\n",
    "       'Augmentations individuelles-Cadres/ingénieurs',\n",
    "       'Augmentations individuelles-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "       'Augmentations individuelles-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations individuelles-Talon (€)',\n",
    "    #    'Augmentations totales (AI + AG)-Toutes catégories confondues ',\n",
    "    #    'Augmentations totales (AI + AG)-Cadres/ingénieurs',\n",
    "    #    'Augmentations totales (AI + AG)-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "    #    'Augmentations totales (AI + AG)-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations totales (AI + AG)-Talon (€)', 'Primes -Pepa ou autres ',\n",
    "       'Primes Pepa ou autres-Montant en € ',\n",
    "    #    'Elements exceptionnels liés à l'inflation ? Prime transport ou autre ',\n",
    "    #    'Commentaires-Divers', 'Lien ', 'Colonne1', \n",
    "       'UrlLegifrance',\n",
    "       'Entreprise', \n",
    "    #    'Siret_y', 'Sous secteur Secafi _y', 'Secteur', 'Naf732',\n",
    "    #    'Date Texte', 'Année application NAO ', 'Tranche Effectif(Base siren)',\n",
    "       'Titre', \n",
    "    #    'Date Maj', 'Date Dépot', 'Date diffusion', 'Date fin',\n",
    "    #    'LesSyndicats', 'LesThemes', 'Raison de non interprétabilité',\n",
    "       'Fichier']].copy()\n",
    "df2_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_r = df2_r.dropna(subset=['Fichier'], axis=0, how='any').reset_index(drop=True)\n",
    "df2_r[\"code\"]=df2_r[\"Fichier\"].str.slice(101,113)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_r = df2_r[[\"Nom de l'entreprise \", \n",
    "        #   'Siret_x', \n",
    "          # \"Date de l'accord du texte\",\n",
    "       'Augmentations générales-Toutes catégories confondues ',\n",
    "       'Augmentations générales-Cadres/ingénieurs',\n",
    "       'Augmentations générales-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "       'Augmentations générales-Ouviers, employés ou autres ',\n",
    "       'Augmentations individuelles-Toutes catégories confondues ',\n",
    "       'Augmentations individuelles-Cadres/ingénieurs',\n",
    "       'Augmentations individuelles-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "       'Augmentations individuelles-Ouviers, employés ou autres ',\n",
    "       'Primes Pepa ou autres-Montant en € ',\n",
    "    #    'UrlLegifrance', \n",
    "    #    'Entreprise', \n",
    "      #  'Titre', \n",
    "      #  'Fichier', \n",
    "       'code']].copy()\n",
    "df2_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df2_r.columns)\n",
    "cols = cols[:1]+cols[-1:]+cols[1:-1]\n",
    "df2_r = df2_r[cols]\n",
    "df2_r.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_pharma_merged.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200_NAO.xlsx of 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\200_NAO.xlsx')\n",
    "df = df[[\n",
    "        # 'UrlLegifrance', \n",
    "         'Code', 'Entreprise', \n",
    "        #  'Secteur SECAFI',\n",
    "       'Augmentations générales-\\nToutes catégories confondues ',\n",
    "       'Augmentations générales\\n-Cadres/ingénieurs',\n",
    "       'Augmentations générales-\\nProfessions intermédiaires',\n",
    "       'Augmentations générales-Ouviers,\\n employés ou autres ',\n",
    "    #    'Augmentations générales\\n-Talon (€)',\n",
    "       'Augmentations individuelles-\\nToutes catégories confondues ',\n",
    "       'Augmentations individuelles\\n-Cadres/ingénieurs',\n",
    "       'Augmentations individuelles-\\nProfessions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "       'Augmentations individuelles\\n-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations\\n individuelles-Talon (€)',\n",
    "    #    'Augmentations totales (AI + AG)-\\nToutes catégories confondues ',\n",
    "    #    'Augmentations totales (AI + AG)-\\nCadres/ingénieurs',\n",
    "    #    'Augmentations totales (AI + AG)-\\nProfessions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "    #    'Augmentations totales (AI + AG)\\n-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations totales \\n(AI + AG)-Talon (€)',\n",
    "    #    'Primes -Pepa ou autres ', \n",
    "       'Primes Pepa ou autres-Montant en € ',\n",
    "    #    'Elements exceptionnels liés à l'inflation ? Prime transport ou autre ',\n",
    "    #    'Commentaires-Divers', 'Lien '\n",
    "       ]].copy()\n",
    "df_r = df.drop(df.index[0]).reset_index(drop=True)\n",
    "df_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df_r.columns)\n",
    "cols = cols[1:2]+cols[0:1]+cols[2:12]\n",
    "df_r = df_r[cols]\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r = df_r.dropna(subset=[\"Code\"], axis=0, how='any').reset_index(drop=True)\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\200_NAO_merged.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAO 2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaping and creating a clean dataset for 2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will first deal with the proapp links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wil merge the two sheets to have all data in one sheet\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\bdd_xlsx\\NAO_2022_proapp.xlsx', sheet_name='Maroquinerie 2022')\n",
    "df1 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\bdd_xlsx\\NAO_2022_proapp.xlsx', sheet_name='Agro 2022')\n",
    "df0 = pd.concat([df, df1], axis=0).reset_index(drop=True)\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['code'] = df0['Fichier'].str.slice(101,113)\n",
    "df0 = df0[[\n",
    "        # 'UrlLegifrance', \n",
    "        'Entreprise', \n",
    "        # 'Siret', 'Groupe', 'Secteur', 'Naf732',\n",
    "        # 'Date Texte', 'Tranche Effectif(Base siren)', \n",
    "        'Fichier',\n",
    "        # 'Pourquoi non exploitable ? ', 'Nature', \n",
    "        'Titre', \n",
    "        # 'Secteur Secafi ',\n",
    "        # 'Agro ? ', 'Sous secteurs BIS', 'Sous secteurs', 'Date Maj',\n",
    "        # 'Date Dépot', 'Date diffusion', 'Date fin', 'LesSyndicats', 'LesThemes',\n",
    "        # 'type', \"Taille d'entreprise BIS\", \"Taille d'entreprise\",\n",
    "        # 'Raison de la non saisie', \n",
    "        'code']].copy()\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.dropna(subset=[\"code\"], axis=0, how='any').reset_index(drop=True)\n",
    "df0.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\bdd_xlsx\\NAO_2022_proapp_cleaned.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then clean as much as possible the collected information for 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\bdd_xlsx\\NAO_2022_saisie.xlsx', sheet_name='Saisie')\n",
    "df2022 = df2022[[\"Nom de l'entreprise \", \n",
    "                #  'Siret', 'Sous secteur Secafi ', 'Secteur NAF ',\n",
    "    #    'Code NAF', \"Date de l'accord du texte\",\n",
    "    #    'Tranche Effectif (Base siren)',\n",
    "       'Augmentations générales-Toutes catégories confondues ',\n",
    "       'Augmentations générales-Cadres/ingénieurs',\n",
    "       'Augmentations générales-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "       'Augmentations générales-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations générales-Talon (€)',\n",
    "       'Augmentations individuelles-Toutes catégories confondues ',\n",
    "       'Augmentations individuelles-Cadres/ingénieurs',\n",
    "       'Augmentations individuelles-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "       'Augmentations individuelles-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations individuelles-Talon (€)',\n",
    "    #    'Augmentations totales (AI + AG)-Toutes catégories confondues ',\n",
    "    #    'Augmentations totales (AI + AG)-Cadres/ingénieurs',\n",
    "    #    'Augmentations totales (AI + AG)-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "    #    'Augmentations totales (AI + AG)-Ouviers, employés ou autres ',\n",
    "    #    'Augmentations totales (AI + AG)-Talon (€)', 'Primes -Pepa ou autres ',\n",
    "    #    'Commentaires-Divers',\n",
    "    #    'Anticipation NAO 2023? Rattrapage inflation ? Deuxième accord ? ',\n",
    "    #    'Lien'\n",
    "       ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_merged = pd.merge(df0, df2022, how='right', right_on=\"Nom de l'entreprise \",left_on='Entreprise')\n",
    "df2022_merged = df2022_merged.dropna(subset=[\"code\"], axis=0, how='any').reset_index(drop=True)\n",
    "df2022_merged[\"PPV\"] = np.nan\n",
    "df2022_merged = df2022_merged[['Entreprise', \n",
    "                            # 'Fichier', \n",
    "                            # 'Titre', \n",
    "                            'code', \n",
    "                            # \"Nom de l'entreprise \",\n",
    "                            'Augmentations générales-Toutes catégories confondues ',\n",
    "                            'Augmentations générales-Cadres/ingénieurs',\n",
    "                            'Augmentations générales-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "                            'Augmentations générales-Ouviers, employés ou autres ',\n",
    "                            'Augmentations individuelles-Toutes catégories confondues ',\n",
    "                            'Augmentations individuelles-Cadres/ingénieurs',\n",
    "                            'Augmentations individuelles-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "                            'Augmentations individuelles-Ouviers, employés ou autres ', 'PPV']].copy()\n",
    "df2022_merged.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\bdd_xlsx\\NAO_2022_merged.xlsx', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\200_NAO_merged.xlsx')\n",
    "df1 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_pharma_merged.xlsx')\n",
    "df2 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_2022_merged.xlsx')\n",
    "\n",
    "column_names = {'Entreprise' : 'entreprise', 'Code' : \"code\",\n",
    "       'Augmentations générales-\\nToutes catégories confondues ' : \"AG\",\n",
    "       'Augmentations générales\\n-Cadres/ingénieurs' : \"AG_cadres\",\n",
    "       'Augmentations générales-\\nProfessions intermédiaires' : \"AG_int\",\n",
    "       'Augmentations générales-Ouviers,\\n employés ou autres ' : \"AG_ouv\",\n",
    "       'Augmentations individuelles-\\nToutes catégories confondues ': \"AI\",\n",
    "       'Augmentations individuelles\\n-Cadres/ingénieurs' : \"AI_cadres\",\n",
    "       'Augmentations individuelles-\\nProfessions intermédiaires (techniciens, agents de maitrise, ou autres) ' : \"AI_int\",\n",
    "       'Augmentations individuelles\\n-Ouviers, employés ou autres ' : \"AI_ouv\",\n",
    "       'Primes Pepa ou autres-Montant en € ' : \"PPV\"}\n",
    "\n",
    "column_names_1 = {\"Nom de l'entreprise \" : 'entreprise', 'Code' : \"code\",\n",
    "       'Augmentations générales-Toutes catégories confondues ' : \"AG\",\n",
    "       'Augmentations générales-Cadres/ingénieurs' : \"AG_cadres\",\n",
    "       'Augmentations générales-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ' : \"AG_int\",\n",
    "       'Augmentations générales-Ouviers, employés ou autres ' : \"AG_ouv\",\n",
    "       'Augmentations individuelles-Toutes catégories confondues ': \"AI\",\n",
    "       'Augmentations individuelles-Cadres/ingénieurs' : \"AI_cadres\",\n",
    "       'Augmentations individuelles-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ' : \"AI_int\",\n",
    "       'Augmentations individuelles-Ouviers, employés ou autres ' : \"AI_ouv\",\n",
    "       'Primes Pepa ou autres-Montant en € ' : \"PPV\"}\n",
    "\n",
    "column_names_2 = {'Entreprise' : 'entreprise', 'code' : \"code\",\n",
    "       'Augmentations générales-Toutes catégories confondues ' : \"AG\",\n",
    "       'Augmentations générales-Cadres/ingénieurs' : \"AG_cadres\",\n",
    "       'Augmentations générales-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ' : \"AG_int\",\n",
    "       'Augmentations générales-Ouviers, employés ou autres ' : \"AG_ouv\",\n",
    "       'Augmentations individuelles-Toutes catégories confondues ': \"AI\",\n",
    "       'Augmentations individuelles-Cadres/ingénieurs' : \"AI_cadres\",\n",
    "       'Augmentations individuelles-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ' : \"AI_int\",\n",
    "       'Augmentations individuelles-Ouviers, employés ou autres ' : \"AI_ouv\",\n",
    "       'PPV' : \"PPV\"}\n",
    "\n",
    "df = df.rename(columns=column_names)\n",
    "df1 = df1.rename(columns=column_names_1)\n",
    "df2 = df2.rename(columns=column_names_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.concat([df, df1, df2], axis = 0, ignore_index=True)\n",
    "df0.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_without_texts.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement text directly into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_without_texts.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective will be to store in a data frame the text. It should be a two columns data frame with the title of the document and the content of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path = r\"C:\\Users\\garsonj\\Desktop\\Finetuning\"\n",
    "directory = glob.glob(os.path.join(path, r'.\\BERT\\cleaned_txt\\*.txt'))\n",
    "\n",
    "# iniate an empty dataframe\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(directory):\n",
    "    # collect the file name and store it in a list\n",
    "    file_name = os.path.basename(file)[:-19]\n",
    "    \n",
    "    # collect the file content and store it in a list\n",
    "    collected_text = []\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        collected_text.append(text)\n",
    "\n",
    "    df = pd.DataFrame(collected_text , columns=['text'])\n",
    "    df.insert(0, 'code', file_name)\n",
    "    final_df = pd.concat([final_df, df], ignore_index=True)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\texts.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we match these texts with their \"accords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\texts.xlsx')\n",
    "df1 = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_without_texts.xlsx')\n",
    "\n",
    "df0 = pd.merge(df, df1, how = 'right', on='code')\n",
    "df0.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_with_texts.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning of the \"NAO_with_texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_with_texts.xlsx')\n",
    "\n",
    "# drop the rows with NaN values\n",
    "df = df.dropna(subset=['code','text'], axis=0, how='any').reset_index(drop=True)\n",
    "\n",
    "# drop the duplicates\n",
    "df = df.drop_duplicates(subset = ['code'], keep = 'first').reset_index(drop=True)\n",
    "\n",
    "# get rid of the blank spaces\n",
    "df = df.replace(r'^\\s*$', '', regex=True)\n",
    "df.to_excel(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\\\BERT\\data\\bdd_xlsx\\NAO_with_texts.xlsx', index=False)\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We prepare our data for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look into their constitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# convert the text column to string type to estimate the length of the texts\n",
    "df = df.astype({\"text\": str})\n",
    "seq = [len(i) for i in df[\"text\"]]\n",
    "df[\"seq\"] = seq\n",
    "\n",
    "threshold = 3000\n",
    "mean_length = np.mean(df[\"seq\"])\n",
    "median_length = np.median(df[\"seq\"])\n",
    "\n",
    "    # plot the histogram\n",
    "    plt.hist(df[\"seq\"], bins=50, color='#86bf91', zorder=2, rwidth=0.9)\n",
    "    plt.title('Distribution of the length of the texts')\n",
    "    plt.xlabel('Number of characters')\n",
    "    plt.ylabel('Number of texts')\n",
    "\n",
    "# add a vertical line for the median length\n",
    "plt.axvline(median_length, color='r', linestyle='dashed', linewidth=1, label='Median Length')\n",
    "plt.axvline(threshold, color='b', linestyle='dashed', linewidth=1, label='Token Threshold')\n",
    "\n",
    "# display the legend\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"limit\"] = df[\"seq\"].apply(lambda x: 1 if x < 3000 else 0)\n",
    "df[\"limit\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above it is an issue that text are long because our model here don't support much more than 1024 tokens (likely) so roughly 3000 characters or between 750-1000 words depending on the tokenizer. So before anything else we should try to make the input shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\training_xlsx\\NAO_texts_for_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prime = df[['code', \n",
    "              'text', \n",
    "              # 'entreprise', 'AG', 'AG_cadres', 'AG_int', 'AG_ouv',\n",
    "              # 'AI', 'AI_cadres', 'AI_int', 'AI_ouv', \n",
    "              'PPV', 'seq', 'limit']].copy()\n",
    "df_prime.to_csv(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\_traing_xlsx\\prime.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate which paragraph to keep either a scoring algorythm or manually. Scoring algorythm would be better since it would allow to generalize it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to Label-Studio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two columns with shortened text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\garsonj\\Desktop\\Finetuning\\BERT\\data\\training_xlsx\\NAO_texts_for_training_raw.csv')[['text','AG']].iloc[:202]\n",
    "\n",
    "df[\"seq\"]=df[\"text\"].apply(lambda x: len(x))\n",
    "threshold = 3000\n",
    "\n",
    "plt.hist((df['seq']), bins=50, color='#86bf91', zorder=2, rwidth=0.9)\n",
    "plt.axvline(threshold, color='b', linestyle='dashed', linewidth=1, label='Token Threshold')\n",
    "plt.show()\n",
    "\n",
    "df = df[['text','AG']].replace(np.nan, 0, regex=True)\n",
    "df['AG'] = df['AG'].str.replace(',', '.').astype(float).replace(np.nan, 0, regex=True).apply(lambda x: x*100)\n",
    "df.head(10)\n",
    "df.to_csv(r'C:\\Users\\garsonj\\Desktop\\NAO_texts_for_training.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one column, because two columns seems not be operative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_csv\\NAO_texts_for_training_F.csv')[['text']].iloc[202:]\n",
    "\n",
    "df.tail(10)\n",
    "df.to_csv(r'C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_csv\\NAO_texts_raw_202_474.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df_comp = pd.read_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\compilation_2023.xlsx\")\n",
    "df_samp = pd.read_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample2023.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp.columns\n",
    "df_samp_final = df_samp[[\n",
    "    'UrlLegifrance', \n",
    "    'Entreprise', \n",
    "    'Siret', \n",
    "    'Secteur', \n",
    "    # 'Nature', \n",
    "    # 'Titre',\n",
    "    'Naf732', \n",
    "    'Date Texte', \n",
    "    # 'Date Maj', \n",
    "    # 'Date Dépot', \n",
    "    # 'Date diffusion',\n",
    "    # 'Date fin', \n",
    "    # 'LesSyndicats', \n",
    "    # 'LesThemes', \n",
    "    # 'type',\n",
    "    'Tranche Effectif(Base siren)', \n",
    "    'Fichier', \n",
    "    # 'ID'\n",
    "    ]].copy()\n",
    "df_samp_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for the application year\n",
    "df_samp_final[\"Année d'application NAO\"] = 2023\n",
    "df_samp_final[\"code\"] = df_samp_final[\"Fichier\"].str.slice(101,113)\n",
    "df_samp_final.head(10)\n",
    "\n",
    "# Reorder the columns\n",
    "df_samp_final.columns\n",
    "df_samp_final = df_samp_final[[\n",
    "    # 'UrlLegifrance',\n",
    "    'code',\n",
    "    'Entreprise', \n",
    "    'Siret', \n",
    "    'Secteur', \n",
    "    'Naf732', \n",
    "    'Date Texte',\n",
    "    \"Année d'application NAO\",\n",
    "    'Tranche Effectif(Base siren)', \n",
    "    ]].copy()\n",
    "\n",
    "# Rename the columns\n",
    "df_samp_final.columns = [\"code\",\"Nom de l'entreprise\", \"Siret\", \"Sous secteur Secafi\", \"Code NAF\", \"Date de l'accord du texte\", \"Année d'application NAO\", \"Tranche Effectif (Base siren)\"]\n",
    "\n",
    "df_samp_final.head(10)\n",
    "df_samp_final.to_excel(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\sample_2023_no_txt.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We adapt the compilation file to the same format\n",
    "\n",
    "df_comp.columns\n",
    "df_comp_final = df_comp[[\n",
    "    \"Nom de l'entreprise \", \n",
    "    'Siret', \n",
    "    'Sous secteur Secafi ', \n",
    "    # 'Secteur NAF ',\n",
    "    'Code NAF', \n",
    "    \"Date de l'accord du texte\", \n",
    "    \"Année d'application NAO\",\n",
    "    'Tranche Effectif (Base siren)',\n",
    "    'Augmentations générales-Toutes catégories confondues ',\n",
    "    'Augmentations générales-Cadres/ingénieurs',\n",
    "    'Augmentations générales-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "    'Augmentations générales-Ouviers, employés ou autres ',\n",
    "    'Augmentations générales-Talon (€)',\n",
    "    'Augmentations individuelles-Toutes catégories confondues ',\n",
    "    'Augmentations individuelles-Cadres/ingénieurs',\n",
    "    'Augmentations individuelles-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "    'Augmentations individuelles-Ouviers, employés ou autres ',\n",
    "    'Augmentations individuelles-Talon (€)',\n",
    "    'Augmentations totales (AI + AG)-Toutes catégories confondues ',\n",
    "    'Augmentations totales (AI + AG)-Cadres/ingénieurs',\n",
    "    'Augmentations totales (AI + AG)-Professions intermédiaires (techniciens, agents de maitrise, ou autres) ',\n",
    "    'Augmentations totales (AI + AG)-Ouviers, employés ou autres ',\n",
    "    'Augmentations totales (AI + AG)-Talon (€)', \n",
    "    'Primes -Pepa ou autres ',\n",
    "    'Primes Pepa ou autres-Montant en € ',\n",
    "    \"Elements exceptionnels liés à l'inflation ? Prime transport ou autre \",\n",
    "    'Commentaires-Divers', \n",
    "    'Lien '\n",
    "    ]].copy()\n",
    "\n",
    "#We change the column names to match the sample file\n",
    "\n",
    "column_names = {\"Nom de l'entreprise \" : \"Nom de l'entreprise\", \"Sous secteur Secafi \":\"Sous secteur Secafi\"}\n",
    "df_comp_final = df_comp_final.rename(columns=column_names)\n",
    "\n",
    "df_comp_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We concat the two files\n",
    "\n",
    "df_final = pd.concat([df_samp_final, df_comp_final], axis=0, ignore_index=True)\n",
    "df_final.to_excel(r'C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\data\\training_xlsx\\NAO_2023.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
