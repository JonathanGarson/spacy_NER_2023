{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier to NER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will first used a model to automate the classification of data and then apply the corresponding NER model to optimize the retrieval process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## specific case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = r'..'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "nlp = spacy.load(os.path.join(ROOT_PATH, r\"model\\classifyer\\PPV\\model-best\"))\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(os.path.join(ROOT_PATH, r\"\\data\\training_csv\\data449_cleaned.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data[\"text\"].tolist()\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    print(doc.cats,  \"-\",  text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppv_list = []\n",
    "nppv_list = []\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    if doc.cats.get(\"PPV\", 0.0) > doc.cats.get(\"NPPV\", 0.0):\n",
    "        ppv_list.append(text)\n",
    "    else:\n",
    "        nppv_list.append(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...to NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(os.path.join(ROOT_PATH, r\"model\\unilabel\\PPV_V2\\model-best\"))  # Select another model to test it\n",
    "\n",
    "# Initialize an empty list to store the output data\n",
    "output_data = []\n",
    "\n",
    "# Loop through items in the directory\n",
    "for item in ppv_list:\n",
    "    # with open(item, \"r\", encoding=\"utf-8\") as file:\n",
    "    #     text = file.read()\n",
    "\n",
    "    doc = nlp_ner(text)\n",
    "    \n",
    "    # Extract labeled information\n",
    "    labeled_data = [\n",
    "        {\n",
    "            \"start\": ent.start_char,\n",
    "            \"end\": ent.end_char,\n",
    "            \"labels\": ent.label_\n",
    "        }\n",
    "        for ent in doc.ents\n",
    "    ]\n",
    "\n",
    "    # Store text and labeled_data as a tuple and append to the output_data list\n",
    "    output_data.append((text, {\"label\": labeled_data}))\n",
    "\n",
    "# Save the labeled data to a JSON file\n",
    "with open(os.path.join(ROOT_PATH, r\"data\\predicted_json\\labeled_data_PPV_class_to_NER.json\"), \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(output_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def classify(classifier_model, data):\n",
    "    \"\"\"\n",
    "    This function takes in text stored in csv file and outputs two lists of text for the different labels.\n",
    "    \n",
    "    args:\n",
    "        classifier_model: the path to the model used to classify the text\n",
    "        data: the path to the csv file containing the text\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the model and data\n",
    "    nlp_classify = spacy.load(classifier_model)\n",
    "    data = pd.read_csv(data)\n",
    "\n",
    "    # Extract the text from the data and class them\n",
    "    texts = data[\"text\"].tolist()\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp_classify(text)\n",
    "        # print(doc.cats,  \"-\",  text)\n",
    "\n",
    "    # Store them in corresponding lists\n",
    "    ppv_list = []\n",
    "    nppv_list = []\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp_classify(text)\n",
    "        if doc.cats.get(\"PPV\", 0.0) > doc.cats.get(\"NPPV\", 0.0):\n",
    "            ppv_list.append(text)\n",
    "        else:\n",
    "            nppv_list.append(text)\n",
    "    return ppv_list, nppv_list\n",
    "\n",
    "def NER(ner_model, list:list):\n",
    "    \"\"\"\n",
    "    This function takes in a list of text and outputs a list of tuples containing the text and the predicted NER labels.\n",
    "\n",
    "    args:\n",
    "        ner_model: the path to the model used to predict the NER labels\n",
    "        list: the list of text to be predicted\n",
    "    \"\"\"\n",
    "    nlp_ner = spacy.load(ner_model)\n",
    "\n",
    "    # Initialize an empty list to store the output data\n",
    "    output_data = []\n",
    "\n",
    "    # Loop through items in the directory\n",
    "    for text in list:\n",
    "        doc = nlp_ner(text)\n",
    "        \n",
    "        # Extract labeled information\n",
    "        labeled_data = [\n",
    "            {\n",
    "                \"start\": ent.start_char,\n",
    "                \"end\": ent.end_char,\n",
    "                \"labels\": ent.label_\n",
    "            }\n",
    "            for ent in doc.ents\n",
    "        ]\n",
    "\n",
    "        # Store text and labeled_data as a tuple and append to the output_data list\n",
    "        output_data.append((text, {\"label\": labeled_data}))\n",
    "    return output_data\n",
    "\n",
    "def open_json(json_file:str):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_NER_to_json(list:list, output_path:str):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(list, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "def json_file_length(json_file:str):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    lenght = len(data)\n",
    "    print(\"Le dossier JSON contient\", lenght, \"éléments.\")\n",
    "\n",
    "def NER_pipeline(classifier_model, ner_model, data_input, output_path):\n",
    "    \"\"\"\n",
    "    This function takes a classifier model, data input, and an output file path.\n",
    "    It classifies the text using the classifier model and then applies the NER model\n",
    "    to the classified text, returning a JSON file of predicted NER labels.\n",
    "\n",
    "    Args:\n",
    "        classifier_model: The path to the model used to classify the text.\n",
    "        ner_model: The path to the model used to predict the NER labels.\n",
    "        data_input: The path to the CSV file containing the text.\n",
    "        output_path: The path to the JSON file to store the predicted NER labels.\n",
    "    \"\"\"\n",
    "    # Use the classify function to classify the data\n",
    "    ppv_list, nppv_list = classify(classifier_model, data_input)\n",
    "\n",
    "    # Use the NER function to predict the NER labels\n",
    "    ppv_output = NER(ner_model, ppv_list)\n",
    "\n",
    "    # Save the predicted NER labels to a JSON file\n",
    "    save_NER_to_json(ppv_output, output_path)\n",
    "\n",
    "    # Print the length of the JSON file\n",
    "    json_file_length(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_mode = os.path.join(ROOT_PATH, r\"model\\classifyer\\PPV\\model-best\")\n",
    "ner_model = os.path.join(ROOT_PATH, r\"model\\unilabel\\PPV_V2\\model-best\")\n",
    "data_input = os.path.join(ROOT_PATH, r\"data\\training_csv\\data449_cleaned.csv\")\n",
    "output_path = os.path.join(ROOT_PATH, r\"data\\predicted_json\\labelled_data_PPV_class_to_NER.json\")\n",
    "\n",
    "NER_pipeline(classifier_model=classifier_mode, ner_model=ner_model, data_input=data_input, output_path=output_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn as sns\n",
    "sys.path.append(r\"C:\\Users\\garsonj\\Desktop\\spacy_finetuning\\spacy_files\\script\")\n",
    "\n",
    "from confusion_matrix_spacy_def import automate_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target labels and the path to the JSON files\n",
    "target_labels = ['PPV']\n",
    "true_json_file = os.path.join(ROOT_PATH, r\"data\\training_json\\data449.json\")\n",
    "pred_json_file = os.path.join(ROOT_PATH, r\"data\\predicted_json\\labelled_data_PPV_class_to_NER.json\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "automate_confusion_matrix(true_json_file, pred_json_file, target_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
